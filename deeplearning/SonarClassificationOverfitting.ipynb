{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0635a2d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:27:22.175586Z",
     "start_time": "2023-02-22T00:27:02.716013Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.0623</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1276</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0050</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1209</td>\n",
       "      <td>0.2467</td>\n",
       "      <td>0.3564</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>0.0105</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.0177</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.2028</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.2328</td>\n",
       "      <td>0.2684</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.2154</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.1258</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>0.1465</td>\n",
       "      <td>0.1123</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1843</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>208 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1       2       3       4       5       6       7       8   \\\n",
       "0    0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1    0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2    0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "3    0.0100  0.0171  0.0623  0.0205  0.0205  0.0368  0.1098  0.1276  0.0598   \n",
       "4    0.0762  0.0666  0.0481  0.0394  0.0590  0.0649  0.1209  0.2467  0.3564   \n",
       "..      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.0187  0.0346  0.0168  0.0177  0.0393  0.1630  0.2028  0.1694  0.2328   \n",
       "204  0.0323  0.0101  0.0298  0.0564  0.0760  0.0958  0.0990  0.1018  0.1030   \n",
       "205  0.0522  0.0437  0.0180  0.0292  0.0351  0.1171  0.1257  0.1178  0.1258   \n",
       "206  0.0303  0.0353  0.0490  0.0608  0.0167  0.1354  0.1465  0.1123  0.1945   \n",
       "207  0.0260  0.0363  0.0136  0.0272  0.0214  0.0338  0.0655  0.1400  0.1843   \n",
       "\n",
       "         9   ...      51      52      53      54      55      56      57  \\\n",
       "0    0.2111  ...  0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1    0.2872  ...  0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2    0.6194  ...  0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "3    0.1264  ...  0.0121  0.0036  0.0150  0.0085  0.0073  0.0050  0.0044   \n",
       "4    0.4459  ...  0.0031  0.0054  0.0105  0.0110  0.0015  0.0072  0.0048   \n",
       "..      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "203  0.2684  ...  0.0116  0.0098  0.0199  0.0033  0.0101  0.0065  0.0115   \n",
       "204  0.2154  ...  0.0061  0.0093  0.0135  0.0063  0.0063  0.0034  0.0032   \n",
       "205  0.2529  ...  0.0160  0.0029  0.0051  0.0062  0.0089  0.0140  0.0138   \n",
       "206  0.2354  ...  0.0086  0.0046  0.0126  0.0036  0.0035  0.0034  0.0079   \n",
       "207  0.2354  ...  0.0146  0.0129  0.0047  0.0039  0.0061  0.0040  0.0036   \n",
       "\n",
       "         58      59  60  \n",
       "0    0.0090  0.0032   R  \n",
       "1    0.0052  0.0044   R  \n",
       "2    0.0095  0.0078   R  \n",
       "3    0.0040  0.0117   R  \n",
       "4    0.0107  0.0094   R  \n",
       "..      ...     ...  ..  \n",
       "203  0.0193  0.0157   M  \n",
       "204  0.0062  0.0067   M  \n",
       "205  0.0077  0.0031   M  \n",
       "206  0.0036  0.0048   M  \n",
       "207  0.0061  0.0115   M  \n",
       "\n",
       "[208 rows x 61 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "\n",
    "# seed 값 설정\n",
    "numpy.random.seed(3)\n",
    "tf.random.set_seed(3)\n",
    "\n",
    "df = pd.read_csv('./datasets/sonar.csv', header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09add807",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:23:32.127667Z",
     "start_time": "2023-02-22T00:23:32.104156Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M    111\n",
       "R     97\n",
       "Name: 60, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[60].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e922f1a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:33:49.188544Z",
     "start_time": "2023-02-22T00:33:33.252800Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 2ms/step - loss: 0.6927 - accuracy: 0.5048\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6723 - accuracy: 0.7019\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6514 - accuracy: 0.6923\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6200 - accuracy: 0.7163\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5872 - accuracy: 0.7740\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7260\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7788\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5017 - accuracy: 0.7596\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.7981\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.8029\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.7933\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8125\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4148 - accuracy: 0.8269\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4044 - accuracy: 0.8173\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3926 - accuracy: 0.8269\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3917 - accuracy: 0.8173\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8510\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3702 - accuracy: 0.8269\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3677 - accuracy: 0.8173\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8413\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3416 - accuracy: 0.8558\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8606\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8413\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8702\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3175 - accuracy: 0.8702\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3039 - accuracy: 0.8894\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3077 - accuracy: 0.8606\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8750\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2866 - accuracy: 0.8942\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2834 - accuracy: 0.8846\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2736 - accuracy: 0.8990\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8894\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2593 - accuracy: 0.9135\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2639 - accuracy: 0.8846\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2517 - accuracy: 0.9135\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2460 - accuracy: 0.9038\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2444 - accuracy: 0.9279\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2391 - accuracy: 0.9038\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2314 - accuracy: 0.9087\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9135\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2321 - accuracy: 0.9038\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2106 - accuracy: 0.9279\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2125 - accuracy: 0.9231\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2181 - accuracy: 0.9183\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2066 - accuracy: 0.9279\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1967 - accuracy: 0.9423\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1862 - accuracy: 0.9423\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9375\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9327\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1795 - accuracy: 0.9471\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.9423\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1630 - accuracy: 0.9519\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1880 - accuracy: 0.9279\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1660 - accuracy: 0.9279\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1558 - accuracy: 0.9471\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1490 - accuracy: 0.9519\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1463 - accuracy: 0.9519\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1487 - accuracy: 0.9471\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1483 - accuracy: 0.9519\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1470 - accuracy: 0.9519\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9567\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9519\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1176 - accuracy: 0.9760\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1203 - accuracy: 0.9567\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9567\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9663\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1307 - accuracy: 0.9519\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1012 - accuracy: 0.9760\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1059 - accuracy: 0.9712\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9760\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0974 - accuracy: 0.9760\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0909 - accuracy: 0.9808\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0843 - accuracy: 0.9856\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9856\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9808\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9808\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9904\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9904\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9856\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0630 - accuracy: 0.9904\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0641 - accuracy: 0.9904\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0683 - accuracy: 0.9856\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0592 - accuracy: 0.9904\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9856\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0578 - accuracy: 0.9904\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9952\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0537 - accuracy: 0.9904\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0571 - accuracy: 0.9904\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0474 - accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0431 - accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0468 - accuracy: 0.9952\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9904\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0447 - accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9952\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0357 - accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0359 - accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0400 - accuracy: 0.9904\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0399 - accuracy: 0.9952\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0286 - accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0276 - accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0290 - accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0245 - accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0270 - accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0243 - accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0247 - accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0218 - accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0217 - accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0178 - accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0184 - accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0153 - accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0147 - accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0150 - accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0136 - accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0132 - accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0134 - accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0117 - accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0096 - accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0088 - accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0084 - accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0077 - accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0072 - accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0075 - accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0062 - accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0102 - accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0076 - accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0048 - accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 9.1503e-04 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 9.4580e-04 - accuracy: 1.0000\n",
      "\n",
      " Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "dataset = df.values\n",
    "x = dataset[:, 0:60]\n",
    "x = np.asarray(x).astype(np.float32) # dtype이 object인데 float으로 변경\n",
    "\n",
    "y_obj = dataset[:, 60]\n",
    "\n",
    "# 문자열 변환\n",
    "e = LabelEncoder()\n",
    "e.fit(y_obj)\n",
    "y = e.transform(y_obj)\n",
    "\n",
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(x, y, epochs=200, batch_size=5)\n",
    "\n",
    "# 결과 출력\n",
    "print('\\n Accuracy: %.4f' % (model.evaluate(x,y)[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558ecd79",
   "metadata": {},
   "source": [
    "학습이 과도하게 많이 되었거나, 학습 데이터와 테스트 데이터가 중복이거나 층이 너무 많을 때, 과대 적합이 생길 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bffb99f",
   "metadata": {},
   "source": [
    " 과대 적합 피하기 - trainset and testset split\n",
    " 학습이 깊어져서 trainset에서만 학습 되면 testset에서 효과가 없다면 과대적합 발생으로 판단\n",
    " fit단계에서 validation_split 파라미터 설정 시 검증 단계 설정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50996fc8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:47:23.573439Z",
     "start_time": "2023-02-22T00:47:04.245771Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 1s 7ms/step - loss: 0.7099 - accuracy: 0.4483 - val_loss: 0.6935 - val_accuracy: 0.3492\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6822 - accuracy: 0.6690 - val_loss: 0.6894 - val_accuracy: 0.4762\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6647 - accuracy: 0.7379 - val_loss: 0.7383 - val_accuracy: 0.1587\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6462 - accuracy: 0.7241 - val_loss: 0.7961 - val_accuracy: 0.0317\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.7172 - val_loss: 0.8474 - val_accuracy: 0.0159\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.6897 - val_loss: 0.9002 - val_accuracy: 0.0159\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5857 - accuracy: 0.6897 - val_loss: 0.9211 - val_accuracy: 0.0476\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5629 - accuracy: 0.7310 - val_loss: 1.0677 - val_accuracy: 0.0159\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5383 - accuracy: 0.7379 - val_loss: 1.0504 - val_accuracy: 0.0476\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7724 - val_loss: 1.0458 - val_accuracy: 0.0952\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.8207 - val_loss: 1.1705 - val_accuracy: 0.0794\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4736 - accuracy: 0.8069 - val_loss: 1.0793 - val_accuracy: 0.2063\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8276 - val_loss: 1.2881 - val_accuracy: 0.1270\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4427 - accuracy: 0.8138 - val_loss: 1.3571 - val_accuracy: 0.1111\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4407 - accuracy: 0.8138 - val_loss: 1.4948 - val_accuracy: 0.0794\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4169 - accuracy: 0.8483 - val_loss: 1.1528 - val_accuracy: 0.2698\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.4027 - accuracy: 0.8345 - val_loss: 1.3331 - val_accuracy: 0.2222\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.8345 - val_loss: 1.5493 - val_accuracy: 0.1270\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8414 - val_loss: 1.2381 - val_accuracy: 0.2857\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3734 - accuracy: 0.8483 - val_loss: 1.4448 - val_accuracy: 0.2381\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3750 - accuracy: 0.8414 - val_loss: 1.5937 - val_accuracy: 0.1746\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3639 - accuracy: 0.8345 - val_loss: 1.2541 - val_accuracy: 0.3492\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8414 - val_loss: 1.6194 - val_accuracy: 0.1905\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8552 - val_loss: 1.3920 - val_accuracy: 0.2698\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8207 - val_loss: 1.0406 - val_accuracy: 0.4603\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8414 - val_loss: 1.4930 - val_accuracy: 0.2698\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8552 - val_loss: 1.4046 - val_accuracy: 0.3492\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8552 - val_loss: 1.5922 - val_accuracy: 0.2540\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8414 - val_loss: 1.6112 - val_accuracy: 0.2698\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3189 - accuracy: 0.8690 - val_loss: 1.5450 - val_accuracy: 0.3175\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8759 - val_loss: 1.6013 - val_accuracy: 0.2857\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3185 - accuracy: 0.8759 - val_loss: 1.4270 - val_accuracy: 0.3651\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8621 - val_loss: 1.4267 - val_accuracy: 0.3651\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8966 - val_loss: 2.0827 - val_accuracy: 0.1746\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8483 - val_loss: 1.3652 - val_accuracy: 0.4127\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.3004 - accuracy: 0.8621 - val_loss: 1.6124 - val_accuracy: 0.3492\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8759 - val_loss: 1.6453 - val_accuracy: 0.3492\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2867 - accuracy: 0.8897 - val_loss: 1.4458 - val_accuracy: 0.4127\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8966 - val_loss: 1.7497 - val_accuracy: 0.3333\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2837 - accuracy: 0.9172 - val_loss: 1.5612 - val_accuracy: 0.3651\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8897 - val_loss: 1.5429 - val_accuracy: 0.3968\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8828 - val_loss: 1.8785 - val_accuracy: 0.2540\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8759 - val_loss: 1.8075 - val_accuracy: 0.3175\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2752 - accuracy: 0.8897 - val_loss: 1.6762 - val_accuracy: 0.3492\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.8897 - val_loss: 1.3386 - val_accuracy: 0.4127\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.9172 - val_loss: 1.7073 - val_accuracy: 0.3492\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.8966 - val_loss: 1.4947 - val_accuracy: 0.4286\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.2545 - accuracy: 0.9241 - val_loss: 1.6407 - val_accuracy: 0.3810\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.9310 - val_loss: 1.6278 - val_accuracy: 0.3968\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2481 - accuracy: 0.9241 - val_loss: 1.6780 - val_accuracy: 0.3810\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2534 - accuracy: 0.9310 - val_loss: 1.9927 - val_accuracy: 0.2698\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2434 - accuracy: 0.9241 - val_loss: 1.6958 - val_accuracy: 0.3810\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2429 - accuracy: 0.9241 - val_loss: 1.7401 - val_accuracy: 0.3810\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2379 - accuracy: 0.9172 - val_loss: 1.5520 - val_accuracy: 0.3968\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2300 - accuracy: 0.9172 - val_loss: 1.8670 - val_accuracy: 0.3492\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2293 - accuracy: 0.9103 - val_loss: 1.2903 - val_accuracy: 0.4444\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2347 - accuracy: 0.9172 - val_loss: 2.0959 - val_accuracy: 0.2540\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2368 - accuracy: 0.9241 - val_loss: 2.0147 - val_accuracy: 0.3492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2247 - accuracy: 0.9379 - val_loss: 1.8533 - val_accuracy: 0.3810\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2135 - accuracy: 0.9310 - val_loss: 1.7126 - val_accuracy: 0.3810\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2153 - accuracy: 0.9379 - val_loss: 1.7051 - val_accuracy: 0.3968\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2064 - accuracy: 0.9310 - val_loss: 1.6840 - val_accuracy: 0.3968\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2107 - accuracy: 0.9379 - val_loss: 1.9183 - val_accuracy: 0.3810\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2005 - accuracy: 0.9241 - val_loss: 2.1431 - val_accuracy: 0.2857\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1976 - accuracy: 0.9379 - val_loss: 1.5938 - val_accuracy: 0.3968\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2040 - accuracy: 0.9379 - val_loss: 1.6789 - val_accuracy: 0.3968\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.2105 - accuracy: 0.9172 - val_loss: 2.3146 - val_accuracy: 0.2540\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1955 - accuracy: 0.9310 - val_loss: 1.7466 - val_accuracy: 0.3810\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9310 - val_loss: 1.5451 - val_accuracy: 0.3968\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1860 - accuracy: 0.9379 - val_loss: 1.8962 - val_accuracy: 0.3333\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1818 - accuracy: 0.9379 - val_loss: 1.8191 - val_accuracy: 0.3810\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1763 - accuracy: 0.9448 - val_loss: 1.9911 - val_accuracy: 0.3333\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1801 - accuracy: 0.9448 - val_loss: 2.3613 - val_accuracy: 0.2857\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1785 - accuracy: 0.9379 - val_loss: 2.1413 - val_accuracy: 0.3175\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1679 - accuracy: 0.9517 - val_loss: 1.9238 - val_accuracy: 0.3492\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1662 - accuracy: 0.9448 - val_loss: 1.9813 - val_accuracy: 0.3651\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1634 - accuracy: 0.9586 - val_loss: 2.0777 - val_accuracy: 0.3333\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1639 - accuracy: 0.9448 - val_loss: 2.2663 - val_accuracy: 0.3016\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1696 - accuracy: 0.9448 - val_loss: 2.2922 - val_accuracy: 0.3016\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1636 - accuracy: 0.9517 - val_loss: 2.2522 - val_accuracy: 0.3016\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1549 - accuracy: 0.9586 - val_loss: 2.0015 - val_accuracy: 0.3492\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1496 - accuracy: 0.9517 - val_loss: 2.3807 - val_accuracy: 0.2857\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1574 - accuracy: 0.9517 - val_loss: 2.0053 - val_accuracy: 0.3651\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1584 - accuracy: 0.9586 - val_loss: 2.4315 - val_accuracy: 0.3016\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1516 - accuracy: 0.9448 - val_loss: 2.3306 - val_accuracy: 0.3016\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1393 - accuracy: 0.9655 - val_loss: 1.7050 - val_accuracy: 0.4286\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1407 - accuracy: 0.9586 - val_loss: 2.1486 - val_accuracy: 0.3492\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1463 - accuracy: 0.9586 - val_loss: 2.4041 - val_accuracy: 0.3016\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1372 - accuracy: 0.9586 - val_loss: 2.1629 - val_accuracy: 0.3492\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1331 - accuracy: 0.9655 - val_loss: 2.0546 - val_accuracy: 0.3651\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1270 - accuracy: 0.9724 - val_loss: 2.1922 - val_accuracy: 0.3492\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1322 - accuracy: 0.9655 - val_loss: 2.5480 - val_accuracy: 0.2857\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1288 - accuracy: 0.9586 - val_loss: 2.0587 - val_accuracy: 0.3810\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1318 - accuracy: 0.9586 - val_loss: 2.3560 - val_accuracy: 0.3492\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1175 - accuracy: 0.9724 - val_loss: 1.8155 - val_accuracy: 0.4286\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1274 - accuracy: 0.9586 - val_loss: 2.3013 - val_accuracy: 0.3492\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1188 - accuracy: 0.9586 - val_loss: 2.2606 - val_accuracy: 0.3492\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1142 - accuracy: 0.9724 - val_loss: 2.1242 - val_accuracy: 0.3651\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1139 - accuracy: 0.9655 - val_loss: 2.0535 - val_accuracy: 0.3810\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9724 - val_loss: 2.2376 - val_accuracy: 0.3492\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1053 - accuracy: 0.9655 - val_loss: 2.4899 - val_accuracy: 0.3492\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1087 - accuracy: 0.9655 - val_loss: 2.0607 - val_accuracy: 0.3810\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1061 - accuracy: 0.9724 - val_loss: 2.3991 - val_accuracy: 0.3492\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1062 - accuracy: 0.9655 - val_loss: 2.3632 - val_accuracy: 0.3492\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0994 - accuracy: 0.9793 - val_loss: 2.2116 - val_accuracy: 0.3810\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.1022 - accuracy: 0.9724 - val_loss: 2.3858 - val_accuracy: 0.3492\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0972 - accuracy: 0.9724 - val_loss: 2.4304 - val_accuracy: 0.3492\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0931 - accuracy: 0.9724 - val_loss: 2.2303 - val_accuracy: 0.3810\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9724 - val_loss: 2.5106 - val_accuracy: 0.3492\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0953 - accuracy: 0.9793 - val_loss: 2.6778 - val_accuracy: 0.3333\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0894 - accuracy: 0.9793 - val_loss: 2.4202 - val_accuracy: 0.3492\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0921 - accuracy: 0.9655 - val_loss: 2.9186 - val_accuracy: 0.3016\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0895 - accuracy: 0.9724 - val_loss: 2.5480 - val_accuracy: 0.3651\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0862 - accuracy: 0.9793 - val_loss: 2.5559 - val_accuracy: 0.3492\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0856 - accuracy: 0.9655 - val_loss: 2.6092 - val_accuracy: 0.3651\n",
      "Epoch 116/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0863 - accuracy: 0.9793 - val_loss: 2.4727 - val_accuracy: 0.3651\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0803 - accuracy: 0.9724 - val_loss: 2.4413 - val_accuracy: 0.3651\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0818 - accuracy: 0.9931 - val_loss: 2.2347 - val_accuracy: 0.3810\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0821 - accuracy: 0.9793 - val_loss: 2.3965 - val_accuracy: 0.3651\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0733 - accuracy: 0.9793 - val_loss: 2.7275 - val_accuracy: 0.3492\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0751 - accuracy: 0.9931 - val_loss: 2.2828 - val_accuracy: 0.3810\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0773 - accuracy: 0.9724 - val_loss: 2.3972 - val_accuracy: 0.3810\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0741 - accuracy: 0.9793 - val_loss: 2.7198 - val_accuracy: 0.3492\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0694 - accuracy: 0.9793 - val_loss: 2.7486 - val_accuracy: 0.3492\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0701 - accuracy: 0.9931 - val_loss: 2.8228 - val_accuracy: 0.3175\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0666 - accuracy: 0.9931 - val_loss: 2.4308 - val_accuracy: 0.3810\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0690 - accuracy: 0.9793 - val_loss: 2.4626 - val_accuracy: 0.3651\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0662 - accuracy: 0.9793 - val_loss: 2.4100 - val_accuracy: 0.3810\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0563 - accuracy: 0.9862 - val_loss: 3.2264 - val_accuracy: 0.2857\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9931 - val_loss: 2.4601 - val_accuracy: 0.3810\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9931 - val_loss: 3.2402 - val_accuracy: 0.3016\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0615 - accuracy: 0.9931 - val_loss: 3.1555 - val_accuracy: 0.3016\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0569 - accuracy: 0.9931 - val_loss: 2.4725 - val_accuracy: 0.3810\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0595 - accuracy: 0.9862 - val_loss: 2.4787 - val_accuracy: 0.3968\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9931 - val_loss: 2.7913 - val_accuracy: 0.3651\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0537 - accuracy: 0.9931 - val_loss: 2.8350 - val_accuracy: 0.3651\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9931 - val_loss: 2.8436 - val_accuracy: 0.3651\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0509 - accuracy: 0.9931 - val_loss: 2.8358 - val_accuracy: 0.3651\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0479 - accuracy: 0.9931 - val_loss: 3.1870 - val_accuracy: 0.3175\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0461 - accuracy: 0.9931 - val_loss: 2.8252 - val_accuracy: 0.3651\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0472 - accuracy: 0.9931 - val_loss: 3.0105 - val_accuracy: 0.3651\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0481 - accuracy: 0.9931 - val_loss: 3.2591 - val_accuracy: 0.3175\n",
      "Epoch 143/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0454 - accuracy: 1.0000 - val_loss: 2.8638 - val_accuracy: 0.3651\n",
      "Epoch 144/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0444 - accuracy: 0.9931 - val_loss: 2.9691 - val_accuracy: 0.3651\n",
      "Epoch 145/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0424 - accuracy: 1.0000 - val_loss: 2.9688 - val_accuracy: 0.3651\n",
      "Epoch 146/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0420 - accuracy: 0.9931 - val_loss: 3.0237 - val_accuracy: 0.3651\n",
      "Epoch 147/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0443 - accuracy: 1.0000 - val_loss: 3.1847 - val_accuracy: 0.3651\n",
      "Epoch 148/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0406 - accuracy: 0.9931 - val_loss: 3.0571 - val_accuracy: 0.3651\n",
      "Epoch 149/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0401 - accuracy: 0.9931 - val_loss: 3.1486 - val_accuracy: 0.3651\n",
      "Epoch 150/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0378 - accuracy: 1.0000 - val_loss: 3.2240 - val_accuracy: 0.3492\n",
      "Epoch 151/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0412 - accuracy: 0.9931 - val_loss: 3.2165 - val_accuracy: 0.3651\n",
      "Epoch 152/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9931 - val_loss: 3.5630 - val_accuracy: 0.3016\n",
      "Epoch 153/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 1.0000 - val_loss: 3.3221 - val_accuracy: 0.3333\n",
      "Epoch 154/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0458 - accuracy: 1.0000 - val_loss: 3.4083 - val_accuracy: 0.3175\n",
      "Epoch 155/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0391 - accuracy: 0.9931 - val_loss: 3.3614 - val_accuracy: 0.3492\n",
      "Epoch 156/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0328 - accuracy: 1.0000 - val_loss: 3.1861 - val_accuracy: 0.3651\n",
      "Epoch 157/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0325 - accuracy: 1.0000 - val_loss: 2.8940 - val_accuracy: 0.3968\n",
      "Epoch 158/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0309 - accuracy: 1.0000 - val_loss: 3.3159 - val_accuracy: 0.3651\n",
      "Epoch 159/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0341 - accuracy: 1.0000 - val_loss: 3.5150 - val_accuracy: 0.3333\n",
      "Epoch 160/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 1.0000 - val_loss: 3.0837 - val_accuracy: 0.3651\n",
      "Epoch 161/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0350 - accuracy: 1.0000 - val_loss: 3.1605 - val_accuracy: 0.3651\n",
      "Epoch 162/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0313 - accuracy: 1.0000 - val_loss: 3.2640 - val_accuracy: 0.3651\n",
      "Epoch 163/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0310 - accuracy: 1.0000 - val_loss: 3.5475 - val_accuracy: 0.3333\n",
      "Epoch 164/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0323 - accuracy: 1.0000 - val_loss: 3.4992 - val_accuracy: 0.3492\n",
      "Epoch 165/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0292 - accuracy: 1.0000 - val_loss: 3.7285 - val_accuracy: 0.3333\n",
      "Epoch 166/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 1.0000 - val_loss: 3.4745 - val_accuracy: 0.3651\n",
      "Epoch 167/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0282 - accuracy: 1.0000 - val_loss: 3.2145 - val_accuracy: 0.3651\n",
      "Epoch 168/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0262 - accuracy: 1.0000 - val_loss: 3.8593 - val_accuracy: 0.3333\n",
      "Epoch 169/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0250 - accuracy: 1.0000 - val_loss: 3.1409 - val_accuracy: 0.3968\n",
      "Epoch 170/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 3.0032 - val_accuracy: 0.4127\n",
      "Epoch 171/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 1.0000 - val_loss: 3.2084 - val_accuracy: 0.3968\n",
      "Epoch 172/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 1.0000 - val_loss: 3.8321 - val_accuracy: 0.3333\n",
      "Epoch 173/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0243 - accuracy: 1.0000 - val_loss: 3.3283 - val_accuracy: 0.3810\n",
      "Epoch 174/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 3.3912 - val_accuracy: 0.3651\n",
      "Epoch 175/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 1.0000 - val_loss: 3.3476 - val_accuracy: 0.3810\n",
      "Epoch 176/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0249 - accuracy: 1.0000 - val_loss: 2.9159 - val_accuracy: 0.4286\n",
      "Epoch 177/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0224 - accuracy: 1.0000 - val_loss: 3.3949 - val_accuracy: 0.3810\n",
      "Epoch 178/200\n",
      "29/29 [==============================] - 0s 4ms/step - loss: 0.0225 - accuracy: 1.0000 - val_loss: 3.6480 - val_accuracy: 0.3651\n",
      "Epoch 179/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0192 - accuracy: 1.0000 - val_loss: 3.3358 - val_accuracy: 0.3968\n",
      "Epoch 180/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0189 - accuracy: 1.0000 - val_loss: 3.8405 - val_accuracy: 0.3333\n",
      "Epoch 181/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 1.0000 - val_loss: 3.1540 - val_accuracy: 0.3968\n",
      "Epoch 182/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0202 - accuracy: 1.0000 - val_loss: 3.4075 - val_accuracy: 0.3810\n",
      "Epoch 183/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0185 - accuracy: 1.0000 - val_loss: 3.5428 - val_accuracy: 0.3810\n",
      "Epoch 184/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0195 - accuracy: 1.0000 - val_loss: 3.9979 - val_accuracy: 0.3333\n",
      "Epoch 185/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 1.0000 - val_loss: 3.7416 - val_accuracy: 0.3651\n",
      "Epoch 186/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0166 - accuracy: 1.0000 - val_loss: 3.2854 - val_accuracy: 0.3968\n",
      "Epoch 187/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0188 - accuracy: 1.0000 - val_loss: 3.7181 - val_accuracy: 0.3651\n",
      "Epoch 188/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0165 - accuracy: 1.0000 - val_loss: 3.6493 - val_accuracy: 0.3810\n",
      "Epoch 189/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 1.0000 - val_loss: 3.8491 - val_accuracy: 0.3651\n",
      "Epoch 190/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0156 - accuracy: 1.0000 - val_loss: 3.6177 - val_accuracy: 0.3968\n",
      "Epoch 191/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0153 - accuracy: 1.0000 - val_loss: 3.9581 - val_accuracy: 0.3492\n",
      "Epoch 192/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0149 - accuracy: 1.0000 - val_loss: 3.4802 - val_accuracy: 0.3968\n",
      "Epoch 193/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0144 - accuracy: 1.0000 - val_loss: 3.9821 - val_accuracy: 0.3492\n",
      "Epoch 194/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 3.4267 - val_accuracy: 0.3968\n",
      "Epoch 195/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0157 - accuracy: 1.0000 - val_loss: 3.7503 - val_accuracy: 0.3810\n",
      "Epoch 196/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 1.0000 - val_loss: 4.1346 - val_accuracy: 0.3492\n",
      "Epoch 197/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 4.0207 - val_accuracy: 0.3492\n",
      "Epoch 198/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0142 - accuracy: 1.0000 - val_loss: 3.9455 - val_accuracy: 0.3810\n",
      "Epoch 199/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 4.1208 - val_accuracy: 0.3492\n",
      "Epoch 200/200\n",
      "29/29 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 4.1943 - val_accuracy: 0.3492\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 1.2783 - accuracy: 0.8029\n",
      "\n",
      " Accuracy: 0.8029\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "history = model.fit(x, y, validation_split=0.3, epochs=200, batch_size=5)\n",
    "\n",
    "# 결과 출력\n",
    "print('\\n Accuracy: %.4f' % (model.evaluate(x,y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3dc6f342",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:48:26.561614Z",
     "start_time": "2023-02-22T00:48:26.557013Z"
    }
   },
   "outputs": [],
   "source": [
    "results = history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2bde3fe4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:50:27.410178Z",
     "start_time": "2023-02-22T00:50:27.305793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(results['accuracy'][0:25], label='accuracy')\n",
    "plt.plot(results['val_loss'][0:25], label='val_loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a912db",
   "metadata": {},
   "source": [
    "20, 24회 정도로 학습 횟수를 조정하면 과대적합을 피하고 오차를 줄일 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5057b6c4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T00:52:31.097961Z",
     "start_time": "2023-02-22T00:52:15.090870Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "42/42 [==============================] - 1s 2ms/step - loss: 0.6902 - accuracy: 0.5577\n",
      "Epoch 2/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.6818 - accuracy: 0.5721\n",
      "Epoch 3/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6723 - accuracy: 0.5577\n",
      "Epoch 4/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6609 - accuracy: 0.5865\n",
      "Epoch 5/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6478 - accuracy: 0.5962\n",
      "Epoch 6/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6342 - accuracy: 0.6202\n",
      "Epoch 7/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.6161 - accuracy: 0.6875\n",
      "Epoch 8/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5959 - accuracy: 0.6971\n",
      "Epoch 9/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5801 - accuracy: 0.7356\n",
      "Epoch 10/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7404\n",
      "Epoch 11/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.7404\n",
      "Epoch 12/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.5018 - accuracy: 0.7788\n",
      "Epoch 13/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.7981\n",
      "Epoch 14/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.7788\n",
      "Epoch 15/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4605 - accuracy: 0.7885\n",
      "Epoch 16/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.7740\n",
      "Epoch 17/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4364 - accuracy: 0.8125\n",
      "Epoch 18/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4319 - accuracy: 0.7692\n",
      "Epoch 19/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4258 - accuracy: 0.8173\n",
      "Epoch 20/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4165 - accuracy: 0.8077\n",
      "Epoch 21/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4110 - accuracy: 0.8365\n",
      "Epoch 22/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.4080 - accuracy: 0.8077\n",
      "Epoch 23/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3891 - accuracy: 0.8317\n",
      "Epoch 24/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3896 - accuracy: 0.8413\n",
      "Epoch 25/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3858 - accuracy: 0.8269\n",
      "Epoch 26/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3750 - accuracy: 0.8510\n",
      "Epoch 27/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3829 - accuracy: 0.8269\n",
      "Epoch 28/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3691 - accuracy: 0.8317\n",
      "Epoch 29/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3721 - accuracy: 0.8365\n",
      "Epoch 30/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3608 - accuracy: 0.8462\n",
      "Epoch 31/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3542 - accuracy: 0.8365\n",
      "Epoch 32/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3719 - accuracy: 0.8221\n",
      "Epoch 33/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8462\n",
      "Epoch 34/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3538 - accuracy: 0.8510\n",
      "Epoch 35/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3331 - accuracy: 0.8510\n",
      "Epoch 36/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8750\n",
      "Epoch 37/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3328 - accuracy: 0.8510\n",
      "Epoch 38/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3406 - accuracy: 0.8654\n",
      "Epoch 39/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3186 - accuracy: 0.8894\n",
      "Epoch 40/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3154 - accuracy: 0.8606\n",
      "Epoch 41/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3198 - accuracy: 0.8606\n",
      "Epoch 42/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8846\n",
      "Epoch 43/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3241 - accuracy: 0.8606\n",
      "Epoch 44/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3242 - accuracy: 0.8510\n",
      "Epoch 45/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3056 - accuracy: 0.8846\n",
      "Epoch 46/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2940 - accuracy: 0.8702\n",
      "Epoch 47/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2951 - accuracy: 0.8894\n",
      "Epoch 48/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.3013 - accuracy: 0.8846\n",
      "Epoch 49/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2952 - accuracy: 0.8894\n",
      "Epoch 50/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2949 - accuracy: 0.8990\n",
      "Epoch 51/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2811 - accuracy: 0.8942\n",
      "Epoch 52/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2846 - accuracy: 0.8846\n",
      "Epoch 53/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2893 - accuracy: 0.8654\n",
      "Epoch 54/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2790 - accuracy: 0.8750\n",
      "Epoch 55/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8942\n",
      "Epoch 56/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2744 - accuracy: 0.8942\n",
      "Epoch 57/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2656 - accuracy: 0.8894\n",
      "Epoch 58/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2678 - accuracy: 0.8750\n",
      "Epoch 59/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2752 - accuracy: 0.8942\n",
      "Epoch 60/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2709 - accuracy: 0.8750\n",
      "Epoch 61/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2596 - accuracy: 0.8990\n",
      "Epoch 62/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2715 - accuracy: 0.8750\n",
      "Epoch 63/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2479 - accuracy: 0.8990\n",
      "Epoch 64/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.9087\n",
      "Epoch 65/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2465 - accuracy: 0.8942\n",
      "Epoch 66/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2445 - accuracy: 0.9135\n",
      "Epoch 67/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2641 - accuracy: 0.8990\n",
      "Epoch 68/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2442 - accuracy: 0.9087\n",
      "Epoch 69/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.9087\n",
      "Epoch 70/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2339 - accuracy: 0.9135\n",
      "Epoch 71/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2425 - accuracy: 0.8750\n",
      "Epoch 72/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2405 - accuracy: 0.9135\n",
      "Epoch 73/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2368 - accuracy: 0.9087\n",
      "Epoch 74/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2266 - accuracy: 0.8990\n",
      "Epoch 75/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2343 - accuracy: 0.9087\n",
      "Epoch 76/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9135\n",
      "Epoch 77/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2202 - accuracy: 0.9279\n",
      "Epoch 78/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2167 - accuracy: 0.9327\n",
      "Epoch 79/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2259 - accuracy: 0.9087\n",
      "Epoch 80/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2037 - accuracy: 0.9183\n",
      "Epoch 81/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2157 - accuracy: 0.9183\n",
      "Epoch 82/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2156 - accuracy: 0.9087\n",
      "Epoch 83/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2005 - accuracy: 0.9231\n",
      "Epoch 84/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2103 - accuracy: 0.9087\n",
      "Epoch 85/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9183\n",
      "Epoch 86/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2080 - accuracy: 0.9135\n",
      "Epoch 87/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1939 - accuracy: 0.9231\n",
      "Epoch 88/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2426 - accuracy: 0.8798\n",
      "Epoch 89/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2153 - accuracy: 0.9135\n",
      "Epoch 90/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.2016 - accuracy: 0.9375\n",
      "Epoch 91/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1907 - accuracy: 0.9327\n",
      "Epoch 92/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1898 - accuracy: 0.9183\n",
      "Epoch 93/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1941 - accuracy: 0.9087\n",
      "Epoch 94/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9183\n",
      "Epoch 95/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1819 - accuracy: 0.9375\n",
      "Epoch 96/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1814 - accuracy: 0.9375\n",
      "Epoch 97/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1876 - accuracy: 0.9471\n",
      "Epoch 98/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1850 - accuracy: 0.9327\n",
      "Epoch 99/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1755 - accuracy: 0.9375\n",
      "Epoch 100/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9231\n",
      "Epoch 101/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9567\n",
      "Epoch 102/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1694 - accuracy: 0.9279\n",
      "Epoch 103/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1778 - accuracy: 0.9135\n",
      "Epoch 104/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1708 - accuracy: 0.9135\n",
      "Epoch 105/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1547 - accuracy: 0.9519\n",
      "Epoch 106/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9471\n",
      "Epoch 107/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1632 - accuracy: 0.9423\n",
      "Epoch 108/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9279\n",
      "Epoch 109/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1549 - accuracy: 0.9519\n",
      "Epoch 110/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1714 - accuracy: 0.9231\n",
      "Epoch 111/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1749 - accuracy: 0.9375\n",
      "Epoch 112/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1511 - accuracy: 0.9375\n",
      "Epoch 113/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1521 - accuracy: 0.9471\n",
      "Epoch 114/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1559 - accuracy: 0.9567\n",
      "Epoch 115/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9567\n",
      "Epoch 116/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9519\n",
      "Epoch 117/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9471\n",
      "Epoch 118/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1460 - accuracy: 0.9471\n",
      "Epoch 119/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1499 - accuracy: 0.9375\n",
      "Epoch 120/200\n",
      "42/42 [==============================] - 0s 1ms/step - loss: 0.1431 - accuracy: 0.9615\n",
      "Epoch 121/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1325 - accuracy: 0.9663\n",
      "Epoch 122/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9423\n",
      "Epoch 123/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1398 - accuracy: 0.9615\n",
      "Epoch 124/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1277 - accuracy: 0.9712\n",
      "Epoch 125/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1281 - accuracy: 0.9519\n",
      "Epoch 126/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1611 - accuracy: 0.9231\n",
      "Epoch 127/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1389 - accuracy: 0.9615\n",
      "Epoch 128/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1233 - accuracy: 0.9615\n",
      "Epoch 129/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1248 - accuracy: 0.9712\n",
      "Epoch 130/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1205 - accuracy: 0.9712\n",
      "Epoch 131/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9471\n",
      "Epoch 132/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1257 - accuracy: 0.9615\n",
      "Epoch 133/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1318 - accuracy: 0.9375\n",
      "Epoch 134/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1211 - accuracy: 0.9615\n",
      "Epoch 135/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1072 - accuracy: 0.9808\n",
      "Epoch 136/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1070 - accuracy: 0.9760\n",
      "Epoch 137/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1073 - accuracy: 0.9808\n",
      "Epoch 138/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1037 - accuracy: 0.9808\n",
      "Epoch 139/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1105 - accuracy: 0.9760\n",
      "Epoch 140/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9760\n",
      "Epoch 141/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9615\n",
      "Epoch 142/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9856\n",
      "Epoch 143/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9712\n",
      "Epoch 144/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1003 - accuracy: 0.9856\n",
      "Epoch 145/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0982 - accuracy: 0.9760\n",
      "Epoch 146/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9760\n",
      "Epoch 147/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9856\n",
      "Epoch 148/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9760\n",
      "Epoch 149/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9904\n",
      "Epoch 150/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0907 - accuracy: 0.9856\n",
      "Epoch 151/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0887 - accuracy: 0.9760\n",
      "Epoch 152/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0847 - accuracy: 0.9904\n",
      "Epoch 153/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0869 - accuracy: 0.9856\n",
      "Epoch 154/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0815 - accuracy: 0.9856\n",
      "Epoch 155/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0841 - accuracy: 0.9856\n",
      "Epoch 156/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0814 - accuracy: 0.9808\n",
      "Epoch 157/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0821 - accuracy: 0.9856\n",
      "Epoch 158/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9808\n",
      "Epoch 159/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0771 - accuracy: 0.9856\n",
      "Epoch 160/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0797 - accuracy: 0.9856\n",
      "Epoch 161/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0739 - accuracy: 0.9904\n",
      "Epoch 162/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0723 - accuracy: 0.9856\n",
      "Epoch 163/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0838 - accuracy: 0.9856\n",
      "Epoch 164/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9904\n",
      "Epoch 165/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0747 - accuracy: 0.9808\n",
      "Epoch 166/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0743 - accuracy: 0.9904\n",
      "Epoch 167/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9904\n",
      "Epoch 168/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0699 - accuracy: 0.9904\n",
      "Epoch 169/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0684 - accuracy: 0.9952\n",
      "Epoch 170/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0665 - accuracy: 0.9904\n",
      "Epoch 171/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0646 - accuracy: 0.9904\n",
      "Epoch 172/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0596 - accuracy: 0.9952\n",
      "Epoch 173/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0655 - accuracy: 0.9904\n",
      "Epoch 174/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0664 - accuracy: 0.9904\n",
      "Epoch 175/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0713 - accuracy: 0.9712\n",
      "Epoch 176/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0782 - accuracy: 0.9760\n",
      "Epoch 177/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0642 - accuracy: 0.9904\n",
      "Epoch 178/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0569 - accuracy: 0.9904\n",
      "Epoch 179/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0620 - accuracy: 0.9952\n",
      "Epoch 181/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0566 - accuracy: 0.9952\n",
      "Epoch 182/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0549 - accuracy: 0.9952\n",
      "Epoch 183/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0497 - accuracy: 0.9952\n",
      "Epoch 185/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0484 - accuracy: 0.9952\n",
      "Epoch 186/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0471 - accuracy: 0.9952\n",
      "Epoch 187/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 0.9952\n",
      "Epoch 188/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0482 - accuracy: 0.9952\n",
      "Epoch 189/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9904\n",
      "Epoch 190/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0530 - accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9952\n",
      "Epoch 192/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0412 - accuracy: 0.9952\n",
      "Epoch 193/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0551 - accuracy: 0.9952\n",
      "Epoch 194/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0501 - accuracy: 0.9904\n",
      "Epoch 195/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0448 - accuracy: 0.9952\n",
      "Epoch 196/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0367 - accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0347 - accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0362 - accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "42/42 [==============================] - 0s 2ms/step - loss: 0.0332 - accuracy: 1.0000\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.0333 - accuracy: 1.0000\n",
      "\n",
      " Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(x, y, epochs=200, batch_size=5)\n",
    "\n",
    "# 결과 출력\n",
    "print('\\n Accuracy: %.4f' % (model.evaluate(x,y)[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a467a9cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-22T01:07:57.018299Z",
     "start_time": "2023-02-22T01:07:49.859035Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/130\n",
      "29/29 [==============================] - 1s 2ms/step - loss: 0.7399 - accuracy: 0.3931\n",
      "Epoch 2/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6804 - accuracy: 0.5793\n",
      "Epoch 3/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.6694 - accuracy: 0.5586\n",
      "Epoch 4/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6520 - accuracy: 0.5586\n",
      "Epoch 5/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6404 - accuracy: 0.6897\n",
      "Epoch 6/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6237 - accuracy: 0.6828\n",
      "Epoch 7/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.6080 - accuracy: 0.6966\n",
      "Epoch 8/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5900 - accuracy: 0.7172\n",
      "Epoch 9/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5694 - accuracy: 0.7862\n",
      "Epoch 10/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.5399 - accuracy: 0.7724\n",
      "Epoch 11/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.7931\n",
      "Epoch 12/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.7793\n",
      "Epoch 13/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8069\n",
      "Epoch 14/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4506 - accuracy: 0.8276\n",
      "Epoch 15/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8414\n",
      "Epoch 16/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4246 - accuracy: 0.8345\n",
      "Epoch 17/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4088 - accuracy: 0.8276\n",
      "Epoch 18/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.4250 - accuracy: 0.8000\n",
      "Epoch 19/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3847 - accuracy: 0.8483\n",
      "Epoch 20/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.3904 - accuracy: 0.8207\n",
      "Epoch 21/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3874 - accuracy: 0.8207\n",
      "Epoch 22/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3730 - accuracy: 0.8414\n",
      "Epoch 23/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3810 - accuracy: 0.8069\n",
      "Epoch 24/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3445 - accuracy: 0.8552\n",
      "Epoch 25/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3539 - accuracy: 0.8621\n",
      "Epoch 26/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8897\n",
      "Epoch 27/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3181 - accuracy: 0.8828\n",
      "Epoch 28/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3226 - accuracy: 0.8828\n",
      "Epoch 29/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.3149 - accuracy: 0.8828\n",
      "Epoch 30/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2975 - accuracy: 0.8966\n",
      "Epoch 31/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2883 - accuracy: 0.8966\n",
      "Epoch 32/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2871 - accuracy: 0.8897\n",
      "Epoch 33/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2831 - accuracy: 0.8828\n",
      "Epoch 34/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8828\n",
      "Epoch 35/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2707 - accuracy: 0.8966\n",
      "Epoch 36/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2665 - accuracy: 0.8966\n",
      "Epoch 37/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2626 - accuracy: 0.8966\n",
      "Epoch 38/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2511 - accuracy: 0.8966\n",
      "Epoch 39/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.8966\n",
      "Epoch 40/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2387 - accuracy: 0.9034\n",
      "Epoch 41/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2371 - accuracy: 0.8966\n",
      "Epoch 42/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2498 - accuracy: 0.8759\n",
      "Epoch 43/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9034\n",
      "Epoch 44/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.2250 - accuracy: 0.9172\n",
      "Epoch 45/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2192 - accuracy: 0.9172\n",
      "Epoch 46/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2079 - accuracy: 0.9241\n",
      "Epoch 47/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2131 - accuracy: 0.9310\n",
      "Epoch 48/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.2047 - accuracy: 0.8966\n",
      "Epoch 49/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1997 - accuracy: 0.9172\n",
      "Epoch 50/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1929 - accuracy: 0.9310\n",
      "Epoch 51/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9310\n",
      "Epoch 52/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1910 - accuracy: 0.9172\n",
      "Epoch 53/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1801 - accuracy: 0.9448\n",
      "Epoch 54/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1811 - accuracy: 0.9448\n",
      "Epoch 55/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1676 - accuracy: 0.9379\n",
      "Epoch 56/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1672 - accuracy: 0.9448\n",
      "Epoch 57/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1618 - accuracy: 0.9448\n",
      "Epoch 58/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1602 - accuracy: 0.9448\n",
      "Epoch 59/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1757 - accuracy: 0.9448\n",
      "Epoch 60/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1496 - accuracy: 0.9448\n",
      "Epoch 61/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1590 - accuracy: 0.9448\n",
      "Epoch 62/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9586\n",
      "Epoch 63/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1743 - accuracy: 0.9310\n",
      "Epoch 64/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9517\n",
      "Epoch 65/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9655\n",
      "Epoch 66/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1428 - accuracy: 0.9586\n",
      "Epoch 67/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9793\n",
      "Epoch 68/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1774 - accuracy: 0.8966\n",
      "Epoch 69/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9448\n",
      "Epoch 70/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1153 - accuracy: 0.9724\n",
      "Epoch 71/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1116 - accuracy: 0.9862\n",
      "Epoch 72/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9724\n",
      "Epoch 73/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9793\n",
      "Epoch 74/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1144 - accuracy: 0.9655\n",
      "Epoch 75/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9724\n",
      "Epoch 76/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1008 - accuracy: 0.9793\n",
      "Epoch 77/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.1101 - accuracy: 0.9586\n",
      "Epoch 78/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9793\n",
      "Epoch 79/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.1076 - accuracy: 0.9724\n",
      "Epoch 80/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0961 - accuracy: 0.9793\n",
      "Epoch 81/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9931\n",
      "Epoch 82/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0883 - accuracy: 1.0000\n",
      "Epoch 83/130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9862\n",
      "Epoch 84/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0828 - accuracy: 0.9862\n",
      "Epoch 85/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0762 - accuracy: 0.9862\n",
      "Epoch 86/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0763 - accuracy: 0.9862\n",
      "Epoch 87/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0805 - accuracy: 0.9793\n",
      "Epoch 88/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0682 - accuracy: 1.0000\n",
      "Epoch 89/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0733 - accuracy: 0.9931\n",
      "Epoch 90/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 1.0000\n",
      "Epoch 91/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0772 - accuracy: 0.9862\n",
      "Epoch 92/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0623 - accuracy: 0.9931\n",
      "Epoch 93/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0675 - accuracy: 0.9931\n",
      "Epoch 94/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0588 - accuracy: 0.9931\n",
      "Epoch 95/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0564 - accuracy: 1.0000\n",
      "Epoch 96/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 1.0000\n",
      "Epoch 97/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0517 - accuracy: 0.9931\n",
      "Epoch 98/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0652 - accuracy: 0.9793\n",
      "Epoch 99/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 1.0000\n",
      "Epoch 100/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0438 - accuracy: 1.0000\n",
      "Epoch 101/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0524 - accuracy: 1.0000\n",
      "Epoch 102/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0572 - accuracy: 1.0000\n",
      "Epoch 103/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0512 - accuracy: 0.9862\n",
      "Epoch 104/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0489 - accuracy: 1.0000\n",
      "Epoch 105/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0506 - accuracy: 1.0000\n",
      "Epoch 106/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0453 - accuracy: 1.0000\n",
      "Epoch 107/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 1.0000\n",
      "Epoch 108/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0418 - accuracy: 1.0000\n",
      "Epoch 109/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0380 - accuracy: 1.0000\n",
      "Epoch 110/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0425 - accuracy: 1.0000\n",
      "Epoch 111/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0351 - accuracy: 1.0000\n",
      "Epoch 112/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0370 - accuracy: 1.0000\n",
      "Epoch 113/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0326 - accuracy: 1.0000\n",
      "Epoch 114/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0339 - accuracy: 1.0000\n",
      "Epoch 115/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0330 - accuracy: 1.0000\n",
      "Epoch 116/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0311 - accuracy: 1.0000\n",
      "Epoch 117/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 118/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0301 - accuracy: 1.0000\n",
      "Epoch 119/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0261 - accuracy: 1.0000\n",
      "Epoch 120/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0291 - accuracy: 1.0000\n",
      "Epoch 121/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 122/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0294 - accuracy: 1.0000\n",
      "Epoch 123/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 1.0000\n",
      "Epoch 124/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 1.0000\n",
      "Epoch 125/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0271 - accuracy: 1.0000\n",
      "Epoch 126/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0249 - accuracy: 1.0000\n",
      "Epoch 127/130\n",
      "29/29 [==============================] - 0s 1ms/step - loss: 0.0226 - accuracy: 1.0000\n",
      "Epoch 128/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0224 - accuracy: 1.0000\n",
      "Epoch 129/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0213 - accuracy: 1.0000\n",
      "Epoch 130/130\n",
      "29/29 [==============================] - 0s 2ms/step - loss: 0.0210 - accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=120)\n",
    "\n",
    "# 모델 설정\n",
    "model = Sequential()\n",
    "model.add(Dense(24, input_dim=60, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='binary_crossentropy',\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 실행\n",
    "model.fit(x_train, y_train, epochs=130, batch_size=5)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d3d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 출력\n",
    "print('\\n Accuracy: %.4f' % (model.evaluate(x_test,y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
